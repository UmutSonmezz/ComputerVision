{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UmutSonmezz/ComputerVision/blob/main/Image_Classification_Tensorflow_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall keras\n",
        "!pip install keras==2.15.0\n",
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "KOEc_JKYOWsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1dzTl8lNo_7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tF8t2UPgPt7z"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44tJ2UDXQmUX"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE=[224,224]\n",
        "train_path='/content/drive/MyDrive/Computer_Vision/train'\n",
        "valid_path='/content/drive/MyDrive/Computer_Vision/validation'\n",
        "test_path='/content/drive/MyDrive/Computer_Vision/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad5n4N_1XRh1"
      },
      "outputs": [],
      "source": [
        "vgg16=VGG16(input_shape = IMAGE_SIZE +[3], weights=\"imagenet\",include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yok5vf4xX-wm"
      },
      "outputs": [],
      "source": [
        "for layer in vgg16.layers:\n",
        "  layer.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwb77Kz0X-zE"
      },
      "outputs": [],
      "source": [
        "folder=glob('/content/drive/MyDrive/Computer_Vision/train/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJKgdqeoaD77"
      },
      "outputs": [],
      "source": [
        "folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBvZWgoHhrcS"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(vgg16)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense (2, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avuqOjMEi3PG"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qq5evMGyjcjQ"
      },
      "outputs": [],
      "source": [
        "#Reproducing data for education\n",
        "train_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "validation_datagen=ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjXQb3GklrAG"
      },
      "outputs": [],
      "source": [
        "#Uploading Tutorial Images\n",
        "training_set=train_datagen.flow_from_directory(\n",
        "\"/content/drive/MyDrive/Computer_Vision/train\",\n",
        "  target_size=(224,224),\n",
        "  batch_size=32,\n",
        "  class_mode=\"categorical\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_9BOmXLxywd"
      },
      "outputs": [],
      "source": [
        "#Uploading Validation Images\n",
        "validation_set = validation_datagen.flow_from_directory(\"/content/drive/MyDrive/Computer_Vision/validation\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_set = validation_datagen.flow_from_directory(\"/content/drive/MyDrive/Computer_Vision/test\",\n",
        "    #target_size=(224, 224),\n",
        "    #class_mode=None)"
      ],
      "metadata": {
        "id": "vDX4wMSEWCYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               patience=3,\n",
        "                               restore_best_weights=True)"
      ],
      "metadata": {
        "id": "QHrpjkZTa6vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMLRyZ1U2Zf4"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    training_set,\n",
        "    validation_data=validation_set,\n",
        "    epochs=10,\n",
        "    steps_per_epoch=training_set.n // training_set.batch_size,\n",
        "    validation_steps=validation_set.n // validation_set.batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-pXEilE2Zh-"
      },
      "outputs": [],
      "source": [
        "history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqXsYSVXRFtf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzg-WsJK_OWD"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'],label=\"train loss\")\n",
        "plt.plot(history.history['val_loss'],label=\"validation loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig(\"loss graph\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save Model\n",
        "model.save(\"model_vgg16.h5\", save_format='h5')"
      ],
      "metadata": {
        "id": "gb-k8wJ8Gzm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade h5py"
      ],
      "metadata": {
        "id": "W3RGb-vtNYYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Model\n",
        "from tensorflow.keras.models import load_model\n",
        "model=load_model(\"/content/drive/MyDrive/Computer_Vision/model_vgg16.h5\")"
      ],
      "metadata": {
        "id": "NtBZkcfYHPPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "def load_test_images(directory, target_size=(224, 224)):\n",
        "    images = []\n",
        "    filenames = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img_path = os.path.join(directory, filename)\n",
        "            img = load_img(img_path, target_size=target_size)\n",
        "            img_array = img_to_array(img)\n",
        "            images.append(img_array)\n",
        "            filenames.append(filename)\n",
        "    return np.array(images), filenames\n",
        "\n",
        "test_dir = \"/content/drive/MyDrive/Computer_Vision/test\"\n",
        "test_images, filenames = load_test_images(test_dir)\n",
        "test_images=test_images / 255.0\n"
      ],
      "metadata": {
        "id": "aNw85cVZatqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Yüklenen test resmi sayısı: {len(test_images)}\")\n",
        "print(f\"Test resimlerinin boyutu: {test_images.shape}\")"
      ],
      "metadata": {
        "id": "bnds1ctmbdAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(test_images)"
      ],
      "metadata": {
        "id": "LmmyMfIyHleV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "ji7rsUpoWuOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=np.argmax(y_pred,axis=1)"
      ],
      "metadata": {
        "id": "W1h88bG7XRn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "QQ_sCKGQcHI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_name = \"/content/drive/MyDrive/Computer_Vision/dog.10455.jpg\""
      ],
      "metadata": {
        "id": "3-fpv-sacHL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img =image.load_img(\"/content/drive/MyDrive/Computer_Vision/dog.10455.jpg\" , target_size=(224, 224))"
      ],
      "metadata": {
        "id": "RALs8KqZmD4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=image.img_to_array(img)\n",
        "x"
      ],
      "metadata": {
        "id": "zF8bUCMVmSds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "DOuQanyXmYX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=x/255"
      ],
      "metadata": {
        "id": "24MIxZ9smkjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "x=np.expand_dims(x,axis=0)\n",
        "img_data=preprocess_input(x)\n",
        "img_data.shape"
      ],
      "metadata": {
        "id": "PY2OKAblmqFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**np.expand_dims(x, axis=0)**: Adds a batch dimension to the image.\n",
        "\n",
        "**preprocess_input(x)**: Processes (normalizes) the image data to be compatible with the VGG16 model.\n",
        "\n",
        "**img_data.shape**: Provides the shape of the processed data, which will typically be (1, 224, 224, 3), indicating that the image is ready to be processed by the model."
      ],
      "metadata": {
        "id": "HTbUJojaqtLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(img_data)"
      ],
      "metadata": {
        "id": "dCZx5eBGm8wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=np.argmax(model.predict(img_data), axis=1)"
      ],
      "metadata": {
        "id": "XePIaIOcnj8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "e8SyUdwTnqyj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "16XD2nssnba5a1KcEDe5R7RtLTWM0JBka",
      "authorship_tag": "ABX9TyO+Ro52FrYDjZTxsXglobAO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}